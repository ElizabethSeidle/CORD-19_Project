{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered Important words list based on TFIDF ranking and min_df and max_df parameters in TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Importing \"preprocess\" collection from mongoDB ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb+srv://group3:group3psu!@squid.36jsw.mongodb.net/CORD19?retryWrites=true&w=majority\")\n",
    "db = client.CORD19\n",
    "db.list_collection_names()\n",
    "a_coll_1017 = db.preprocess\n",
    "a_1017 = pd.DataFrame(list(a_coll_1017.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57921 entries, 0 to 57920\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   _id             57921 non-null  object        \n",
      " 1   level_0         57921 non-null  int64         \n",
      " 2   index           57921 non-null  int64         \n",
      " 3   abstract        57921 non-null  object        \n",
      " 4   authors         57921 non-null  object        \n",
      " 5   journal         57921 non-null  object        \n",
      " 6   license         57921 non-null  object        \n",
      " 7   publish_time    57921 non-null  datetime64[ns]\n",
      " 8   title           57921 non-null  object        \n",
      " 9   language        57921 non-null  object        \n",
      " 10  word_count      57921 non-null  int64         \n",
      " 11  char_count      57921 non-null  int64         \n",
      " 12  sent_count      57921 non-null  int64         \n",
      " 13  avg_word_len    57921 non-null  float64       \n",
      " 14  stopwords       57921 non-null  int64         \n",
      " 15  cleanAbtstract  57921 non-null  object        \n",
      " 16  bert_abstract   57921 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(9)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "a_1017 .head()\n",
    "a_1017 .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### abstract_string_conversion #####\n",
    "def convert_list_to_string(list, seperator=' '):\n",
    "    return seperator.join(list)\n",
    "a_1017 ['ab_string'] = a_1017 ['cleanAbtstract'].apply(lambda row: convert_list_to_string(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Abstracts\n",
    "w2 = []\n",
    "for i in range(0,len(a_1017 .index)):\n",
    "    abstract = a_1017['ab_string'].iloc[i]\n",
    "    w2.append(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Frequency TF-IDF Words ( Post initial preprocessing and cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           term           rank\n",
      "14      sarscov  114642.131032\n",
      "7        infect   96980.206139\n",
      "0          case   91525.154771\n",
      "17          use   83439.447491\n",
      "16        studi   82755.186967\n",
      "10       pandem   80545.510483\n",
      "15        sever   79833.063131\n",
      "5        health   75675.105791\n",
      "1        clinic   71523.932391\n",
      "13       result   65370.330207\n",
      "3          data   58794.198501\n",
      "12  respiratori   57363.643948\n",
      "11       report   56748.136069\n",
      "6        includ   54516.022902\n",
      "4        effect   53276.887718\n",
      "8           may   52323.752786\n",
      "9        method   47931.056963\n",
      "2       conclus   39746.847315\n"
     ]
    }
   ],
   "source": [
    "##### tf-idf calc from sklearn max_df=.50, min_df=.25 ###\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.50, min_df=.25, stop_words=None, use_idf=True, norm=None)\n",
    "vectors = vectorizer.fit_transform(w2)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "sums = vectors.sum(axis=0) #sum tf-idf for each term throughout\n",
    "\n",
    "#connects term and sum freq\n",
    "data = []\n",
    "for col, term in enumerate(feature_names):\n",
    "    data.append((term,sums[0,col]))\n",
    "\n",
    "##### Output: tf-idf sorted descending top 50\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank']) \n",
    "print(ranking.sort_values('rank', ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen above notable words in above list are \"sarscov\" and \"respiratori\" indicating relation of COVID with these and covid mainly being a respiratori disease. \n",
    "- Note that this list does not contain other more frequently expected words such as covid,coronavirus,patient etc. since either they have already been filtered in preprocessing \n",
    "- or because the min and max parameters of TFIDF vectorizer has been set to include min 25 % of document and max 50% of documents in which term/word appears. \n",
    "- So even though list mentions \"High Frequency\" its still actually a filtered list of more meaningful words with frequency between 25% to 50% only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Frequency TF-IDF words ( Post initial preprocessing and cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          term          rank\n",
      "118       test  69455.338458\n",
      "52      hospit  63346.997991\n",
      "105       risk  63004.132501\n",
      "16        care  62801.121377\n",
      "73       model  58368.422630\n",
      "122  treatment  55886.237337\n",
      "30         day  55512.007733\n",
      "126      virus  55040.111518\n",
      "12      associ  52321.073044\n",
      "58      increa  51372.844623\n",
      "48       group  51008.226685\n",
      "115    symptom  50677.632025\n",
      "119       time  48238.207948\n",
      "108     signif  47819.754817\n",
      "78      number  47597.912646\n",
      "97        rate  47270.647929\n",
      "71      measur  45575.842860\n",
      "1         acut  45146.865558\n",
      "34     develop  45037.748402\n",
      "88       posit  44759.570538\n",
      "35      differ  44585.347394\n",
      "91     present  44362.120884\n",
      "94      provid  44090.735397\n",
      "82    outbreak  44035.302137\n",
      "27     countri  43260.749374\n"
     ]
    }
   ],
   "source": [
    "##### tf-idf calc from sklearn max_df=.25, min_df=.10 ###\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.25, min_df=.10, stop_words=None, use_idf=True, norm=None)\n",
    "vectors = vectorizer.fit_transform(w2)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "sums = vectors.sum(axis=0) #sum tf-idf for each term throughout\n",
    "\n",
    "#connects term and sum freq\n",
    "data = []\n",
    "for col, term in enumerate(feature_names):\n",
    "    data.append((term,sums[0,col]))\n",
    "\n",
    "##### Output: tf-idf sorted descending top 25\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank']) \n",
    "print(ranking.sort_values('rank', ascending=False).head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interestingly as mentioned above the most notable word in above list is \"test\" matching with the general heavy emphasis laid on testing to control the corona virus.\n",
    "- Above list is based on 10% to 25% of documents in which the word appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Frequency / Most Important TF-IDF words ( Post initial preprocessing and cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 term          rank\n",
      "3009               de  11109.688327\n",
      "5281              hcq   9400.837220\n",
      "5289             hcws   9255.124813\n",
      "11980           sleep   8953.559133\n",
      "3696               ed   8646.216369\n",
      "8370           neonat   8622.283205\n",
      "3146           dental   8225.223836\n",
      "5659               hr   7878.742953\n",
      "9948           pollut   7831.321859\n",
      "2630           counti   7658.397115\n",
      "10788          recipi   7364.630511\n",
      "13184     tocilizumab   7192.569300\n",
      "9893               pm   7174.235803\n",
      "4021           epitop   6934.654800\n",
      "10692             rbd   6853.277005\n",
      "12855      telehealth   6690.017065\n",
      "8872              nsp   6576.977265\n",
      "11256              rr   6516.621467\n",
      "2603   corticosteroid   6465.988314\n",
      "13959         variant   6351.195289\n",
      "13170          tmprss   6316.278782\n",
      "317               aki   6231.120296\n",
      "14141         vitamin   6062.090747\n",
      "7693               mg   6051.544232\n",
      "10885       rehabilit   6034.005133\n",
      "6841               la   6021.769205\n",
      "3474            donor   6008.607201\n",
      "9007        olfactori   5967.158577\n",
      "5526              hiv   5921.119608\n",
      "7490           matern   5900.370609\n",
      "4115           ethnic   5849.276216\n",
      "8061             mpro   5815.300589\n",
      "13334          trauma   5675.493252\n",
      "234            africa   5648.999226\n",
      "5623        hospitali   5609.010290\n",
      "8475             news   5558.772104\n",
      "9575           peptid   5497.411716\n",
      "14062           video   5495.375480\n",
      "750               app   5427.628714\n",
      "2427           confin   5361.588653\n",
      "8036           mother   5355.379432\n",
      "9413           parent   5322.864155\n",
      "9162          orthopa   5246.500128\n",
      "3369        disinfect   5209.835621\n",
      "8910           nutrit   5169.802922\n",
      "11020          respir   5165.313585\n",
      "8051             mous   5162.717341\n",
      "10431       psychiatr   5152.285042\n",
      "9854         platelet   5142.000323\n",
      "2279         coinfect   5102.592086\n"
     ]
    }
   ],
   "source": [
    "##### tf-idf calc from sklearn max_df=.01, min_df=.0001 ###\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.01, min_df=.0001, stop_words=None, use_idf=True, norm=None)\n",
    "vectors = vectorizer.fit_transform(w2)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "sums = vectors.sum(axis=0) #sum tf-idf for each term throughout\n",
    "\n",
    "#connects term and sum freq\n",
    "data = []\n",
    "for col, term in enumerate(feature_names):\n",
    "    data.append((term,sums[0,col]))\n",
    "\n",
    "##### Output: tf-idf sorted descending top 50\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank']) \n",
    "print(ranking.sort_values('rank', ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above list is based on terms/words appearing in .01 to 1% of documents\n",
    "- Although above frequency seems too low, since we have a dataset of around 58000 documents, its still a good frequency to get more meaningful targeted data we are looking for such as names of most used medicines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 50 highest ranking TF-IDF words from this list does throw us name of medicines such as \"hcq\", \"tocilizumab\" both arthritis drugs which were being tried on patients with severe COVID-19 patients at the time to which data set belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
