{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb+srv://group3:group3psu!@squid.36jsw.mongodb.net/CORD19?retryWrites=true&w=majority\")\n",
    "db = client.CORD19\n",
    "db.list_collection_names()\n",
    "collection = db.preprocess\n",
    "clean = collection.find()\n",
    "df = pd.DataFrame(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for i in range(0,len(df.index)):\n",
    "    abstract = df[\"abstract_tfidf\"].iloc[i]\n",
    "    w.append(abstract)\n",
    "\n",
    "listToStr = ''.join([str(elem) for elem in w])\n",
    "tokens = nltk.word_tokenize(listToStr)\n",
    "len(tokens) # total words for reference\n",
    "len(set(tokens)) # unique words for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output of parts of speech. This website is helpful for key:\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "VB.. and JJ.. are the code for different types of verbs and adjectives and NN.. is for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tag_fd = nltk.FreqDist(tag for (word,tag) in tagged)\n",
    "tag_fd.most_common() #output of part of speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Verbs and Adjectives\n",
    "tagged_VADJ = [x for (x,y) in tagged if y in ('VBP', 'VB', 'VBD', 'VBZ', 'VBN', 'VBG', \n",
    "                                         'JJ', 'JJR', 'JJS')] \n",
    "VADJ_uniq = list(set(tagged_VADJ)) #set of above to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Nouns\n",
    "tagged_NN = [x for (x,y) in tagged if y in ('NN')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_final = [x for x in w if x not in VADJ_uniq]\n",
    "\n",
    "#out of order, I realized afterwards that \"background\" should be removed\n",
    "y =['background\\s+']\n",
    "abstract_final = [(lambda x: re.sub(r'|'.join(y), '', x))(x) for x in abstract_final] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(abstract_final, columns=['abstract_final'])\n",
    "df2['_id'] = df2.index\n",
    "df2 = df2[['_id','abstract_final']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempts That Did Not Work. Took Too Long & Never Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = set(tokens) - set(tagged_VADJ) #unique words to keep\n",
    "remove_words = [x for x in w if x not in keep_words] #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option1: works on small set, but left it running overnight and never completed\n",
    "for x, elem in enumerate(w):\n",
    "    w[x] = \" \".join(filter(lambda x: x not in keep_words, elem.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option2: works on small set, but never completed\n",
    "pat = '|'.join([r'\\b{}\\b'.format(i) for i in remove_words])\n",
    "df['abtract_final'] = df['abstract_tfidf'].str.replace(pat,'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############### push out to MongoDB\n",
    "\n",
    "### testing on Scratch\n",
    "db = client.CORD19\n",
    "db.list_collection_names()\n",
    "collection = db.scratch # <---- change to preprocess\n",
    "\n",
    "##### \n",
    "\n",
    "cursor = collection.find()\n",
    " \n",
    "for document in cursor:\n",
    "    id = document[\"_id\"]\n",
    "    record = df2.loc[(df2['_id'] == id)]\n",
    "    abstract_final = record[\"abstract_final\"]\n",
    "    abstract_final = document.get(\"abstract_final\")\n",
    " \n",
    "    if abstract_final is None:\n",
    "        collection.update_one({\"_id\": id}, {\"$set\": {\"abstract_final\": abstract_final}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
