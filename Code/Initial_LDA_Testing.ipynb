{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ear51\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\ear51\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "C:\\Users\\ear51\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import itertools\n",
    "from langdetect import detect\n",
    "import seaborn as sns\n",
    "\n",
    "#!pip install gensim\n",
    "#!pip install pyLDAvis\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "#!pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scratch', 'clean', 'preprocess', 'working2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient(\"mongodb+srv://group3:group3psu!@squid.36jsw.mongodb.net/CORD19?retryWrites=true&w=majority\")\n",
    "db = client.CORD19\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57921 entries, 0 to 57920\n",
      "Data columns (total 16 columns):\n",
      "_id               57921 non-null object\n",
      "level_0           57921 non-null int64\n",
      "index             57921 non-null int64\n",
      "abstract          57921 non-null object\n",
      "authors           57921 non-null object\n",
      "journal           57921 non-null object\n",
      "license           57921 non-null object\n",
      "publish_time      57921 non-null datetime64[ns]\n",
      "title             57921 non-null object\n",
      "language          57921 non-null object\n",
      "word_count        57921 non-null int64\n",
      "char_count        57921 non-null int64\n",
      "sent_count        57921 non-null int64\n",
      "avg_word_len      57921 non-null float64\n",
      "stopwords         57921 non-null int64\n",
      "cleanAbtstract    57921 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(8)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "collection_clean = db.preprocess\n",
    "mongo_df_clean = pd.DataFrame(list(collection_clean.find()))\n",
    "df_1 = mongo_df_clean \n",
    "df_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove high-content words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Modelling - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 7), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 4), (9, 1), (10, 6), (11, 6), (12, 1), (13, 3), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 8), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 3), (29, 1), (30, 9), (31, 1), (32, 1), (33, 1), (34, 2), (35, 2), (36, 1), (37, 3), (38, 1), (39, 5), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 5), (48, 1), (49, 2), (50, 1), (51, 1), (52, 7), (53, 7), (54, 5), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 3), (64, 1), (65, 3), (66, 1), (67, 2), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 2), (76, 6), (77, 4), (78, 1), (79, 3)]]\n"
     ]
    }
   ],
   "source": [
    "#Create a Gensim dictionary from the tokenized data \n",
    "cleaned = df_1['cleanAbtstract']\n",
    "\n",
    "#Creating term dictionary of corpus, where each unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(cleaned)\n",
    "\n",
    "#Filter terms which occurs in less than 1 answer and more than X% of the abstracts.\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.4)\n",
    "\n",
    "#convert the dictionary to a bag of words corpus \n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in cleaned]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('adjust', 1),\n",
       "  ('analyz', 2),\n",
       "  ('anxieti', 7),\n",
       "  ('anxious', 1),\n",
       "  ('assign', 1),\n",
       "  ('associ', 1),\n",
       "  ('averag', 1),\n",
       "  ('background', 1),\n",
       "  ('cg', 4),\n",
       "  ('chang', 1),\n",
       "  ('chd', 6),\n",
       "  ('chi', 6),\n",
       "  ('common', 1),\n",
       "  ('compar', 3),\n",
       "  ('conclus', 1),\n",
       "  ('control', 1),\n",
       "  ('coronari', 2),\n",
       "  ('correl', 1),\n",
       "  ('cox', 1),\n",
       "  ('day', 1),\n",
       "  ('depress', 8),\n",
       "  ('differ', 1),\n",
       "  ('disea', 1),\n",
       "  ('effect', 2),\n",
       "  ('emot', 1),\n",
       "  ('exerci', 1),\n",
       "  ('exert', 1),\n",
       "  ('explor', 1),\n",
       "  ('form', 3),\n",
       "  ('function', 1),\n",
       "  ('group', 9),\n",
       "  ('hand', 1),\n",
       "  ('health', 1),\n",
       "  ('heart', 1),\n",
       "  ('higher', 2),\n",
       "  ('improv', 2),\n",
       "  ('increa', 1),\n",
       "  ('interv', 3),\n",
       "  ('item', 1),\n",
       "  ('level', 5),\n",
       "  ('life', 1),\n",
       "  ('lower', 1),\n",
       "  ('may', 1),\n",
       "  ('meanwhil', 1),\n",
       "  ('measur', 1),\n",
       "  ('medic', 1),\n",
       "  ('method', 1),\n",
       "  ('mir', 5),\n",
       "  ('model', 1),\n",
       "  ('month', 2),\n",
       "  ('negat', 1),\n",
       "  ('outcom', 1),\n",
       "  ('p', 7),\n",
       "  ('patient', 7),\n",
       "  ('pci', 5),\n",
       "  ('percutan', 1),\n",
       "  ('proport', 1),\n",
       "  ('protect', 1),\n",
       "  ('qpcr', 1),\n",
       "  ('qualiti', 1),\n",
       "  ('random', 1),\n",
       "  ('realtim', 1),\n",
       "  ('receiv', 1),\n",
       "  ('relat', 3),\n",
       "  ('result', 1),\n",
       "  ('score', 3),\n",
       "  ('serum', 1),\n",
       "  ('sf', 2),\n",
       "  ('shortform', 1),\n",
       "  ('signif', 1),\n",
       "  ('stress', 2),\n",
       "  ('studi', 1),\n",
       "  ('subject', 1),\n",
       "  ('subscal', 2),\n",
       "  ('survey', 1),\n",
       "  ('symptom', 2),\n",
       "  ('tai', 6),\n",
       "  ('tg', 4),\n",
       "  ('upregul', 1),\n",
       "  ('use', 3)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.020*\"pandem\" + 0.014*\"health\" + 0.012*\"care\" + 0.007*\"provid\" + 0.006*\"patient\" + 0.006*\"disea\" + 0.006*\"use\" + 0.006*\"manag\" + 0.006*\"medic\" + 0.005*\"healthcar\" + 0.005*\"system\" + 0.005*\"need\" + 0.005*\"impact\" + 0.005*\"practic\" + 0.005*\"public\" + 0.005*\"coronavirus\" + 0.005*\"emerg\" + 0.004*\"risk\" + 0.004*\"respon\" + 0.004*\"challeng\"')\n",
      "(1, '0.024*\"test\" + 0.023*\"sarscov\" + 0.016*\"patient\" + 0.012*\"use\" + 0.012*\"infect\" + 0.011*\"posit\" + 0.011*\"detect\" + 0.010*\"result\" + 0.009*\"sampl\" + 0.008*\"method\" + 0.008*\"perform\" + 0.007*\"surgeri\" + 0.006*\"coronavirus\" + 0.006*\"assay\" + 0.006*\"respiratori\" + 0.006*\"surgic\" + 0.006*\"viral\" + 0.006*\"clinic\" + 0.005*\"negat\" + 0.005*\"studi\"')\n",
      "(2, '0.015*\"case\" + 0.009*\"model\" + 0.009*\"infect\" + 0.009*\"studi\" + 0.008*\"data\" + 0.008*\"use\" + 0.008*\"number\" + 0.007*\"result\" + 0.007*\"countri\" + 0.007*\"rate\" + 0.007*\"measur\" + 0.006*\"health\" + 0.006*\"epidem\" + 0.006*\"report\" + 0.006*\"outbreak\" + 0.006*\"disea\" + 0.006*\"popul\" + 0.006*\"china\" + 0.005*\"spread\" + 0.005*\"death\"')\n",
      "(3, '0.027*\"sarscov\" + 0.016*\"coronavirus\" + 0.013*\"infect\" + 0.011*\"virus\" + 0.009*\"sever\" + 0.009*\"respiratori\" + 0.009*\"disea\" + 0.009*\"cell\" + 0.008*\"drug\" + 0.008*\"viral\" + 0.007*\"syndrom\" + 0.007*\"protein\" + 0.007*\"human\" + 0.007*\"caus\" + 0.006*\"immun\" + 0.006*\"vaccin\" + 0.006*\"use\" + 0.006*\"acut\" + 0.006*\"potenti\" + 0.006*\"effect\"')\n",
      "(4, '0.053*\"patient\" + 0.014*\"disea\" + 0.013*\"sever\" + 0.011*\"clinic\" + 0.010*\"studi\" + 0.010*\"hospit\" + 0.009*\"p\" + 0.008*\"case\" + 0.007*\"risk\" + 0.007*\"associ\" + 0.007*\"infect\" + 0.007*\"group\" + 0.007*\"symptom\" + 0.006*\"outcom\" + 0.006*\"includ\" + 0.006*\"day\" + 0.006*\"treatment\" + 0.006*\"result\" + 0.006*\"coronavirus\" + 0.006*\"mortal\"')\n"
     ]
    }
   ],
   "source": [
    "#Declare number of topics\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 5, id2word=dictionary, passes=30)\n",
    "ldamodel.save('model_combined.gensim')\n",
    "\n",
    "#Declare number of keywords to use for each topic\n",
    "topics = ldamodel.print_topics(num_words=20)\n",
    "for topic in topics:\n",
    "   print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.41073945), (3, 0.10123838), (4, 0.48556602)]\n"
     ]
    }
   ],
   "source": [
    "get_document_topics = ldamodel.get_document_topics(corpus[0])\n",
    "print(get_document_topics) #entry 0 is x% related to topic n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_topic(ldamodel, corpus, texts):\n",
    "     #Function to find the dominant topic in each review\n",
    "     sent_topics_df = pd.DataFrame() \n",
    "     # Get main topic in each review\n",
    "     for i, row in enumerate(ldamodel[corpus]):\n",
    "         row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "         # Get the Dominant topic, Perc Contribution and Keywords for each review\n",
    "         for j, (topic_num, prop_topic) in enumerate(row):\n",
    "             if j == 0:  # =&gt; dominant topic\n",
    "                 wp = ldamodel.show_topic(topic_num,topn=4)\n",
    "                 topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                 sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "             else:\n",
    "                 break\n",
    "     sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "     contents = pd.Series(texts)\n",
    "     sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "     return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>patient, disea, sever, clinic</td>\n",
       "      <td>background anxiety depression common symptoms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>patient, disea, sever, clinic</td>\n",
       "      <td>counterregulatory arm renin angiotensin system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>sarscov, coronavirus, infect, virus</td>\n",
       "      <td>several studies suggested baricitinib potentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>pandem, health, care, provid</td>\n",
       "      <td>background aims healthcare delivery requires s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>pandem, health, care, provid</td>\n",
       "      <td>coronavirus disease covid19 presents two urgen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dominant_Topic  Perc_Contribution                       Topic_Keywords  \\\n",
       "0             4.0             0.4856        patient, disea, sever, clinic   \n",
       "1             4.0             0.6390        patient, disea, sever, clinic   \n",
       "2             3.0             0.6416  sarscov, coronavirus, infect, virus   \n",
       "3             0.0             0.6721         pandem, health, care, provid   \n",
       "4             0.0             0.8732         pandem, health, care, provid   \n",
       "\n",
       "                                            abstract  \n",
       "0  background anxiety depression common symptoms ...  \n",
       "1  counterregulatory arm renin angiotensin system...  \n",
       "2  several studies suggested baricitinib potentia...  \n",
       "3  background aims healthcare delivery requires s...  \n",
       "4  coronavirus disease covid19 presents two urgen...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic = dominant_topic(ldamodel=ldamodel, corpus=corpus, texts=df_1['abstract']) \n",
    "df_dominant_topic.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
