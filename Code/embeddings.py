# -*- coding: utf-8 -*-
"""embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vUrXuc45GdW_pZuMbx1sVjDBx6CLkHEE
"""

!pip install dnspython
!pip install sentence_transformers

"""Set-up"""

import pymongo
client = pymongo.MongoClient("mongodb+srv://scott:bluegreen50@squid.36jsw.mongodb.net/CORD19?retryWrites=true&w=majority")
db = client.CORD19
collection = db.preprocess

import pprint

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('distilbert-base-nli-mean-tokens')

"""Run encodings on each document"""

cursor = collection.find()
#cursor.count()

for document in cursor:
    id = document["_id"]
    abstract = document["abstract"]
    #pprint.pprint(abstract)
    bert_abstract = document.get("bert_abstract")

    if bert_abstract is None:
      embedding = model.encode(abstract, show_progress_bar=False)
      #print(type(embedding))
      #print(embedding)
      collection.update_one({"_id": id}, {"$set": {"bert_abstract": embedding.tolist()}})

print(collection.find({}).count())
print(collection.find({"bert_abstract": {"$exists":"true"}}).count())

source = db.preprocess_tfidf
target = db.preprocess

cursor = target.find({"abstract_tfidf": {"$exists":False}})
#print(cursor.count())

for document in cursor:
    id = document["_id"]
    #print(id)
    matched_tfidf = source.find({"_id": id})
    #print(matched_tfidf.count())
    for matched in matched_tfidf:
      #print(matched["abstract_tfidf"])
      tfidf = matched["abstract_tfidf"]
      target.update_one({"_id":id}, {"$set": {"abstract_tfidf": tfidf}})

print(target.find({}).count())
print(target.find({"abstract_tfidf": {"$exists":"true"}}).count())